package cache

import (
	"context"
	"fmt"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"go.uber.org/zap"
)

// PrefetchStrategy é¢„å–ç­–ç•¥
type PrefetchStrategy interface {
	// ShouldPrefetch åˆ¤æ–­æ˜¯å¦åº”è¯¥é¢„å–
	ShouldPrefetch(key string, accessPattern *AccessPattern) bool

	// GeneratePrefetchKeys ç”Ÿæˆé¢„å–é”®
	GeneratePrefetchKeys(key string, accessPattern *AccessPattern) []string

	// GetStrategyName è·å–ç­–ç•¥åç§°
	GetStrategyName() string
}

// AccessPattern è®¿é—®æ¨¡å¼
type AccessPattern struct {
	Key          string
	AccessCount  int64
	LastAccess   time.Time
	AccessTimes  []time.Time
	Neighbors    []string      // ç›¸å…³çš„é”®
	AccessRate   float64       // è®¿é—®é¢‘ç‡
	TimeInterval time.Duration // å¹³å‡è®¿é—®é—´éš”
}

// Prefetcher é¢„å–å™¨
type Prefetcher struct {
	config *CacheConfig
	cache  *SmartCache
	logger *zap.Logger

	// è®¿é—®æ¨¡å¼è·Ÿè¸ª
	patterns   map[string]*AccessPattern
	patternMux sync.RWMutex

	// é¢„å–ç­–ç•¥
	strategies []PrefetchStrategy

	// å·¥ä½œé˜Ÿåˆ—
	prefetchQueue chan *PrefetchRequest
	workers       []chan struct{} // ç”¨äºåœæ­¢worker

	// ç»Ÿè®¡ä¿¡æ¯
	stats struct {
		prefetchRequests atomic.Int64
		prefetchHits     atomic.Int64
		prefetchMisses   atomic.Int64
		prefetchWasted   atomic.Int64 // é¢„å–ä½†æœªä½¿ç”¨çš„é¡¹
		patternUpdates   atomic.Int64
		totalPrefetched  atomic.Int64
	}

	// æ§åˆ¶
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// PrefetchRequest é¢„å–è¯·æ±‚
type PrefetchRequest struct {
	Key       string
	Priority  int
	Strategy  string
	Metadata  map[string]interface{}
	Callback  func(key string, success bool, err error)
	CreatedAt time.Time
}

// NewPrefetcher åˆ›å»ºé¢„å–å™¨
func NewPrefetcher(config *CacheConfig, cache *SmartCache) *Prefetcher {
	prefetcher := &Prefetcher{
		config:        config,
		cache:         cache,
		logger:        zap.L().Named("prefetcher"),
		patterns:      make(map[string]*AccessPattern),
		prefetchQueue: make(chan *PrefetchRequest, config.PrefetchWorkers*10),
		workers:       make([]chan struct{}, config.PrefetchWorkers),
	}

	// åˆå§‹åŒ–é¢„å–ç­–ç•¥
	prefetcher.strategies = []PrefetchStrategy{
		NewSequentialPrefetchStrategy(),
		NewSpatialPrefetchStrategy(),
		NewTemporalPrefetchStrategy(),
		NewMLPrefetchStrategy(),
	}

	return prefetcher
}

// Start å¯åŠ¨é¢„å–å™¨
func (p *Prefetcher) Start(ctx context.Context) error {
	p.ctx, p.cancel = context.WithCancel(ctx)

	// å¯åŠ¨å·¥ä½œåç¨‹
	for i := 0; i < p.config.PrefetchWorkers; i++ {
		stopChan := make(chan struct{})
		p.workers[i] = stopChan

		p.wg.Add(1)
		go p.worker(i, stopChan)
	}

	// å¯åŠ¨æ¨¡å¼åˆ†æåç¨‹
	p.wg.Add(1)
	go p.patternAnalyzer()

	// å¯åŠ¨æ¸…ç†åç¨‹
	p.wg.Add(1)
	go p.cleanup()

	p.logger.Info("ğŸ”® é¢„å–å™¨å¯åŠ¨",
		zap.Int("workers", p.config.PrefetchWorkers),
		zap.Int("strategies", len(p.strategies)),
		zap.Float64("threshold", p.config.PrefetchThreshold))

	return nil
}

// Stop åœæ­¢é¢„å–å™¨
func (p *Prefetcher) Stop() error {
	p.logger.Info("ğŸ›‘ æ­£åœ¨åœæ­¢é¢„å–å™¨...")

	if p.cancel != nil {
		p.cancel()
	}

	// åœæ­¢æ‰€æœ‰å·¥ä½œåç¨‹
	for _, stopChan := range p.workers {
		close(stopChan)
	}

	// å…³é—­é¢„å–é˜Ÿåˆ—
	close(p.prefetchQueue)

	// ç­‰å¾…æ‰€æœ‰åç¨‹ç»“æŸ
	p.wg.Wait()

	p.logger.Info("âœ… é¢„å–å™¨å·²åœæ­¢")
	return nil
}

// OnHit å¤„ç†ç¼“å­˜å‘½ä¸­
func (p *Prefetcher) OnHit(key string) {
	p.updateAccessPattern(key, true)
	p.triggerPrefetch(key)
}

// OnMiss å¤„ç†ç¼“å­˜æœªå‘½ä¸­
func (p *Prefetcher) OnMiss(key string) {
	p.updateAccessPattern(key, false)
	p.triggerPrefetch(key)
}

// updateAccessPattern æ›´æ–°è®¿é—®æ¨¡å¼
func (p *Prefetcher) updateAccessPattern(key string, hit bool) {
	p.patternMux.Lock()
	defer p.patternMux.Unlock()

	pattern, exists := p.patterns[key]
	if !exists {
		pattern = &AccessPattern{
			Key:         key,
			AccessTimes: make([]time.Time, 0, 10),
			Neighbors:   make([]string, 0),
		}
		p.patterns[key] = pattern
	}

	now := time.Now()
	pattern.AccessCount++
	pattern.LastAccess = now
	pattern.AccessTimes = append(pattern.AccessTimes, now)

	// ä¿æŒæœ€è¿‘çš„è®¿é—®æ—¶é—´
	if len(pattern.AccessTimes) > 10 {
		pattern.AccessTimes = pattern.AccessTimes[1:]
	}

	// è®¡ç®—è®¿é—®é¢‘ç‡å’Œé—´éš”
	if len(pattern.AccessTimes) > 1 {
		totalInterval := pattern.AccessTimes[len(pattern.AccessTimes)-1].Sub(pattern.AccessTimes[0])
		pattern.TimeInterval = totalInterval / time.Duration(len(pattern.AccessTimes)-1)
		pattern.AccessRate = float64(len(pattern.AccessTimes)) / totalInterval.Seconds()
	}

	p.stats.patternUpdates.Add(1)
}

// triggerPrefetch è§¦å‘é¢„å–
func (p *Prefetcher) triggerPrefetch(key string) {
	p.patternMux.RLock()
	pattern, exists := p.patterns[key]
	p.patternMux.RUnlock()

	if !exists {
		return
	}

	// ä½¿ç”¨å„ç§ç­–ç•¥ç”Ÿæˆé¢„å–è¯·æ±‚
	for _, strategy := range p.strategies {
		if strategy.ShouldPrefetch(key, pattern) {
			prefetchKeys := strategy.GeneratePrefetchKeys(key, pattern)

			for _, prefetchKey := range prefetchKeys {
				// æ£€æŸ¥æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­
				if p.cache.Exists(prefetchKey) {
					continue
				}

				request := &PrefetchRequest{
					Key:       prefetchKey,
					Priority:  p.calculatePriority(prefetchKey, pattern),
					Strategy:  strategy.GetStrategyName(),
					Metadata:  map[string]interface{}{"original_key": key},
					CreatedAt: time.Now(),
				}

				select {
				case p.prefetchQueue <- request:
					p.stats.prefetchRequests.Add(1)
				default:
					// é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒè¯·æ±‚
				}
			}
		}
	}
}

// calculatePriority è®¡ç®—é¢„å–ä¼˜å…ˆçº§
func (p *Prefetcher) calculatePriority(key string, pattern *AccessPattern) int {
	priority := 5 // é»˜è®¤ä¼˜å…ˆçº§

	// åŸºäºè®¿é—®é¢‘ç‡è°ƒæ•´
	if pattern.AccessRate > 1.0 { // æ¯ç§’è¶…è¿‡1æ¬¡
		priority += 3
	} else if pattern.AccessRate > 0.1 { // æ¯ç§’è¶…è¿‡0.1æ¬¡
		priority += 1
	}

	// åŸºäºè®¿é—®é—´éš”è°ƒæ•´
	if pattern.TimeInterval < 1*time.Minute {
		priority += 2
	} else if pattern.TimeInterval < 5*time.Minute {
		priority += 1
	}

	return priority
}

// worker é¢„å–å·¥ä½œåç¨‹
func (p *Prefetcher) worker(id int, stopChan chan struct{}) {
	defer p.wg.Done()

	p.logger.Debug("å¯åŠ¨é¢„å–å·¥ä½œåç¨‹", zap.Int("worker_id", id))

	for {
		select {
		case request := <-p.prefetchQueue:
			p.processPrefetchRequest(request)

		case <-stopChan:
			p.logger.Debug("é¢„å–å·¥ä½œåç¨‹åœæ­¢", zap.Int("worker_id", id))
			return

		case <-p.ctx.Done():
			return
		}
	}
}

// processPrefetchRequest å¤„ç†é¢„å–è¯·æ±‚
func (p *Prefetcher) processPrefetchRequest(request *PrefetchRequest) {
	// æ£€æŸ¥æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­
	if p.cache.Exists(request.Key) {
		p.stats.prefetchHits.Add(1)
		if request.Callback != nil {
			request.Callback(request.Key, true, nil)
		}
		return
	}

	// æ‰§è¡Œé¢„å–é€»è¾‘
	success, err := p.performPrefetch(request)

	if success {
		p.stats.prefetchHits.Add(1)
		p.stats.totalPrefetched.Add(1)
	} else {
		p.stats.prefetchMisses.Add(1)
	}

	if request.Callback != nil {
		request.Callback(request.Key, success, err)
	}

	p.logger.Debug("é¢„å–è¯·æ±‚å¤„ç†å®Œæˆ",
		zap.String("key", request.Key),
		zap.String("strategy", request.Strategy),
		zap.Bool("success", success),
		zap.Error(err))
}

// performPrefetch æ‰§è¡Œé¢„å–
func (p *Prefetcher) performPrefetch(request *PrefetchRequest) (bool, error) {
	// è¿™é‡Œæ˜¯é¢„å–çš„å…·ä½“å®ç°
	// å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨æ•°æ®æºè·å–æ•°æ®
	// ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„é¢„å–é€»è¾‘

	// æ¨¡æ‹Ÿæ•°æ®è·å–
	data := []byte(fmt.Sprintf("prefetched-data-for-%s", request.Key))

	// è®¾ç½®è¾ƒçŸ­çš„TTLç”¨äºé¢„å–æ•°æ®
	prefetchTTL := p.config.DefaultTTL / 2

	// å­˜å‚¨åˆ°ç¼“å­˜
	err := p.cache.Set(request.Key, data, prefetchTTL)
	return err == nil, err
}

// patternAnalyzer æ¨¡å¼åˆ†æå™¨
func (p *Prefetcher) patternAnalyzer() {
	defer p.wg.Done()

	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.analyzePatterns()
		case <-p.ctx.Done():
			return
		}
	}
}

// analyzePatterns åˆ†æè®¿é—®æ¨¡å¼
func (p *Prefetcher) analyzePatterns() {
	p.patternMux.Lock()
	defer p.patternMux.Unlock()

	now := time.Now()
	var activePatterns int

	// åˆ†ææ‰€æœ‰æ¨¡å¼ï¼Œå¯»æ‰¾ç›¸å…³æ€§
	for key, pattern := range p.patterns {
		// æ£€æŸ¥æ¨¡å¼æ˜¯å¦è¿‡æœŸ
		if now.Sub(pattern.LastAccess) > 1*time.Hour {
			delete(p.patterns, key)
			continue
		}

		activePatterns++

		// å¯»æ‰¾ç›¸å…³çš„é”®ï¼ˆç®€å•çš„å‰ç¼€åŒ¹é…ï¼‰
		p.findRelatedKeys(pattern)
	}

	p.logger.Debug("æ¨¡å¼åˆ†æå®Œæˆ", zap.Int("active_patterns", activePatterns))
}

// findRelatedKeys å¯»æ‰¾ç›¸å…³é”®
func (p *Prefetcher) findRelatedKeys(pattern *AccessPattern) {
	pattern.Neighbors = pattern.Neighbors[:0] // æ¸…ç©º

	// ç®€å•çš„ç›¸å…³æ€§åˆ†æï¼šåŸºäºé”®çš„å‰ç¼€
	keyPrefix := extractPrefix(pattern.Key)

	for key := range p.patterns {
		if key != pattern.Key && strings.HasPrefix(key, keyPrefix) {
			pattern.Neighbors = append(pattern.Neighbors, key)
			if len(pattern.Neighbors) >= 5 { // é™åˆ¶é‚»å±…æ•°é‡
				break
			}
		}
	}
}

// extractPrefix æå–é”®å‰ç¼€
func extractPrefix(key string) string {
	// ç®€å•å®ç°ï¼šè¿”å›æœ€åä¸€ä¸ªæ–œæ ä¹‹å‰çš„éƒ¨åˆ†
	if lastSlash := strings.LastIndex(key, "/"); lastSlash > 0 {
		return key[:lastSlash+1]
	}
	return key
}

// cleanup æ¸…ç†è¿‡æœŸæ•°æ®
func (p *Prefetcher) cleanup() {
	defer p.wg.Done()

	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			p.cleanupExpiredPatterns()
		case <-p.ctx.Done():
			return
		}
	}
}

// cleanupExpiredPatterns æ¸…ç†è¿‡æœŸæ¨¡å¼
func (p *Prefetcher) cleanupExpiredPatterns() {
	p.patternMux.Lock()
	defer p.patternMux.Unlock()

	now := time.Now()
	var cleaned int

	for key, pattern := range p.patterns {
		if now.Sub(pattern.LastAccess) > 2*time.Hour {
			delete(p.patterns, key)
			cleaned++
		}
	}

	if cleaned > 0 {
		p.logger.Debug("æ¸…ç†è¿‡æœŸè®¿é—®æ¨¡å¼", zap.Int("cleaned", cleaned))
	}
}

// GetStats è·å–é¢„å–å™¨ç»Ÿè®¡
func (p *Prefetcher) GetStats() map[string]interface{} {
	p.patternMux.RLock()
	patternCount := len(p.patterns)
	p.patternMux.RUnlock()

	prefetchRequests := p.stats.prefetchRequests.Load()
	prefetchHits := p.stats.prefetchHits.Load()

	var prefetchHitRate float64
	if prefetchRequests > 0 {
		prefetchHitRate = float64(prefetchHits) / float64(prefetchRequests)
	}

	return map[string]interface{}{
		"prefetch_requests": prefetchRequests,
		"prefetch_hits":     prefetchHits,
		"prefetch_misses":   p.stats.prefetchMisses.Load(),
		"prefetch_hit_rate": prefetchHitRate,
		"prefetch_wasted":   p.stats.prefetchWasted.Load(),
		"pattern_updates":   p.stats.patternUpdates.Load(),
		"total_prefetched":  p.stats.totalPrefetched.Load(),
		"active_patterns":   patternCount,
		"queue_size":        len(p.prefetchQueue),
		"strategies":        len(p.strategies),
	}
}

// é¢„å–ç­–ç•¥å®ç°

// SequentialPrefetchStrategy é¡ºåºé¢„å–ç­–ç•¥
type SequentialPrefetchStrategy struct{}

func NewSequentialPrefetchStrategy() *SequentialPrefetchStrategy {
	return &SequentialPrefetchStrategy{}
}

func (s *SequentialPrefetchStrategy) ShouldPrefetch(key string, pattern *AccessPattern) bool {
	// å¦‚æœè®¿é—®é¢‘ç‡è¾ƒé«˜ï¼Œè€ƒè™‘é¡ºåºé¢„å–
	return pattern.AccessCount > 2 && pattern.AccessRate > 0.1
}

func (s *SequentialPrefetchStrategy) GeneratePrefetchKeys(key string, pattern *AccessPattern) []string {
	var keys []string

	// å°è¯•ç”Ÿæˆé¡ºåºé”®
	if strings.Contains(key, "_") {
		parts := strings.Split(key, "_")
		if len(parts) > 1 {
			// å°è¯•è§£ææœ€åä¸€éƒ¨åˆ†ä¸ºæ•°å­—
			lastPart := parts[len(parts)-1]
			if len(lastPart) > 0 {
				// ç®€å•çš„æ•°å­—é€’å¢
				for i := 1; i <= 3; i++ {
					newKey := strings.Join(parts[:len(parts)-1], "_") + fmt.Sprintf("_%s%d", lastPart, i)
					keys = append(keys, newKey)
				}
			}
		}
	}

	return keys
}

func (s *SequentialPrefetchStrategy) GetStrategyName() string {
	return "sequential"
}

// SpatialPrefetchStrategy ç©ºé—´é¢„å–ç­–ç•¥
type SpatialPrefetchStrategy struct{}

func NewSpatialPrefetchStrategy() *SpatialPrefetchStrategy {
	return &SpatialPrefetchStrategy{}
}

func (s *SpatialPrefetchStrategy) ShouldPrefetch(key string, pattern *AccessPattern) bool {
	return len(pattern.Neighbors) > 0
}

func (s *SpatialPrefetchStrategy) GeneratePrefetchKeys(key string, pattern *AccessPattern) []string {
	// è¿”å›ç›¸å…³çš„é‚»å±…é”®
	return pattern.Neighbors
}

func (s *SpatialPrefetchStrategy) GetStrategyName() string {
	return "spatial"
}

// TemporalPrefetchStrategy æ—¶é—´é¢„å–ç­–ç•¥
type TemporalPrefetchStrategy struct{}

func NewTemporalPrefetchStrategy() *TemporalPrefetchStrategy {
	return &TemporalPrefetchStrategy{}
}

func (s *TemporalPrefetchStrategy) ShouldPrefetch(key string, pattern *AccessPattern) bool {
	// åŸºäºæ—¶é—´é—´éš”çš„é¢„æµ‹
	return pattern.TimeInterval > 0 && pattern.TimeInterval < 5*time.Minute
}

func (s *TemporalPrefetchStrategy) GeneratePrefetchKeys(key string, pattern *AccessPattern) []string {
	// åŸºäºæ—¶é—´æ¨¡å¼ç”Ÿæˆé”®
	// è¿™é‡Œç®€åŒ–å®ç°
	var keys []string

	if strings.Contains(key, "daily") {
		// é¢„å–æ˜å¤©çš„æ•°æ®
		keys = append(keys, strings.Replace(key, "daily", "daily_tomorrow", 1))
	}

	return keys
}

func (s *TemporalPrefetchStrategy) GetStrategyName() string {
	return "temporal"
}

// MLPrefetchStrategy æœºå™¨å­¦ä¹ é¢„å–ç­–ç•¥
type MLPrefetchStrategy struct{}

func NewMLPrefetchStrategy() *MLPrefetchStrategy {
	return &MLPrefetchStrategy{}
}

func (s *MLPrefetchStrategy) ShouldPrefetch(key string, pattern *AccessPattern) bool {
	// ç®€åŒ–çš„MLå†³ç­–ï¼šåŸºäºå¤šä¸ªå› ç´ çš„ç»¼åˆè¯„åˆ†
	score := 0.0

	// è®¿é—®é¢‘ç‡å› å­
	if pattern.AccessRate > 1.0 {
		score += 0.4
	} else if pattern.AccessRate > 0.5 {
		score += 0.2
	}

	// è®¿é—®è§„å¾‹æ€§å› å­
	if pattern.TimeInterval > 0 && pattern.TimeInterval < 10*time.Minute {
		score += 0.3
	}

	// ç›¸å…³æ€§å› å­
	if len(pattern.Neighbors) > 2 {
		score += 0.3
	}

	return score > 0.6
}

func (s *MLPrefetchStrategy) GeneratePrefetchKeys(key string, pattern *AccessPattern) []string {
	// ç»“åˆå¤šç§ç­–ç•¥ç”Ÿæˆé¢„å–é”®
	keys := make([]string, 0)

	// æ·»åŠ é‚»å±…é”®
	keys = append(keys, pattern.Neighbors...)

	// æ·»åŠ æ¨¡å¼æ¨å¯¼çš„é”®
	if strings.Contains(key, "/") {
		parts := strings.Split(key, "/")
		if len(parts) > 1 {
			// ç”ŸæˆåŒçº§åˆ«çš„ç›¸å…³é”®
			base := strings.Join(parts[:len(parts)-1], "/")
			keys = append(keys, base+"/related_1", base+"/related_2")
		}
	}

	return keys
}

func (s *MLPrefetchStrategy) GetStrategyName() string {
	return "ml"
}



