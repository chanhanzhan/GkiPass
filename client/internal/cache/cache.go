package cache

import (
	"context"
	"crypto/md5"
	"errors"
	"fmt"
	"sync"
	"sync/atomic"
	"time"

	"go.uber.org/zap"
)

var (
	ErrCacheNotFound = errors.New("cache not found")
	ErrCacheExpired  = errors.New("cache expired")
	ErrCacheFull     = errors.New("cache is full")
)

// CacheConfig ç¼“å­˜é…ç½®
type CacheConfig struct {
	// åŸºæœ¬é…ç½®
	MaxSize       int64         `json:"max_size"`       // æœ€å¤§ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	MaxEntries    int           `json:"max_entries"`    // æœ€å¤§æ¡ç›®æ•°
	DefaultTTL    time.Duration `json:"default_ttl"`    // é»˜è®¤TTL
	CleanInterval time.Duration `json:"clean_interval"` // æ¸…ç†é—´éš”

	// ç­–ç•¥é…ç½®
	EvictionPolicy string  `json:"eviction_policy"` // æ·˜æ±°ç­–ç•¥: lru, lfu, fifo, random
	LoadFactor     float64 `json:"load_factor"`     // è´Ÿè½½å› å­

	// é¢„å–é…ç½®
	EnablePrefetch    bool    `json:"enable_prefetch"`    // å¯ç”¨é¢„å–
	PrefetchThreshold float64 `json:"prefetch_threshold"` // é¢„å–é˜ˆå€¼
	PrefetchWindow    int     `json:"prefetch_window"`    // é¢„å–çª—å£å¤§å°
	PrefetchWorkers   int     `json:"prefetch_workers"`   // é¢„å–å·¥ä½œåç¨‹æ•°

	// æ€§èƒ½é…ç½®
	EnableCompression bool `json:"enable_compression"` // å¯ç”¨å‹ç¼©
	CompressionLevel  int  `json:"compression_level"`  // å‹ç¼©çº§åˆ«
	EnableSharding    bool `json:"enable_sharding"`    // å¯ç”¨åˆ†ç‰‡
	ShardCount        int  `json:"shard_count"`        // åˆ†ç‰‡æ•°é‡

	// æŒä¹…åŒ–é…ç½®
	EnablePersistence bool          `json:"enable_persistence"` // å¯ç”¨æŒä¹…åŒ–
	PersistencePath   string        `json:"persistence_path"`   // æŒä¹…åŒ–è·¯å¾„
	SyncInterval      time.Duration `json:"sync_interval"`      // åŒæ­¥é—´éš”
}

// DefaultCacheConfig é»˜è®¤ç¼“å­˜é…ç½®
func DefaultCacheConfig() *CacheConfig {
	return &CacheConfig{
		MaxSize:           100 * 1024 * 1024, // 100MB
		MaxEntries:        10000,
		DefaultTTL:        1 * time.Hour,
		CleanInterval:     5 * time.Minute,
		EvictionPolicy:    "lru",
		LoadFactor:        0.75,
		EnablePrefetch:    true,
		PrefetchThreshold: 0.8,
		PrefetchWindow:    10,
		PrefetchWorkers:   2,
		EnableCompression: true,
		CompressionLevel:  6,
		EnableSharding:    true,
		ShardCount:        16,
		EnablePersistence: false,
		PersistencePath:   "/tmp/cache",
		SyncInterval:      30 * time.Second,
	}
}

// CacheEntry ç¼“å­˜æ¡ç›®
type CacheEntry struct {
	Key         string
	Value       []byte
	Size        int64
	TTL         time.Duration
	CreatedAt   time.Time
	AccessedAt  time.Time
	AccessCount int64
	Compressed  bool

	// LRUé“¾è¡¨èŠ‚ç‚¹
	prev *CacheEntry
	next *CacheEntry
}

// IsExpired æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
func (e *CacheEntry) IsExpired() bool {
	if e.TTL <= 0 {
		return false
	}
	return time.Since(e.CreatedAt) > e.TTL
}

// Age è·å–å¹´é¾„
func (e *CacheEntry) Age() time.Duration {
	return time.Since(e.CreatedAt)
}

// SmartCache æ™ºèƒ½ç¼“å­˜
type SmartCache struct {
	config *CacheConfig
	logger *zap.Logger

	// åˆ†ç‰‡ç¼“å­˜
	shards    []*CacheShard
	shardMask uint64

	// é¢„å–å™¨
	prefetcher *Prefetcher

	// ç»Ÿè®¡ä¿¡æ¯
	stats struct {
		hits         atomic.Int64
		misses       atomic.Int64
		evictions    atomic.Int64
		prefetches   atomic.Int64
		currentSize  atomic.Int64
		currentCount atomic.Int64
	}

	// æ§åˆ¶
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup
}

// CacheShard ç¼“å­˜åˆ†ç‰‡
type CacheShard struct {
	mutex       sync.RWMutex
	entries     map[string]*CacheEntry
	lruHead     *CacheEntry
	lruTail     *CacheEntry
	currentSize int64
	maxSize     int64
	maxEntries  int
	policy      EvictionPolicy
}

// EvictionPolicy æ·˜æ±°ç­–ç•¥æ¥å£
type EvictionPolicy interface {
	OnAccess(entry *CacheEntry)
	OnAdd(entry *CacheEntry)
	OnEvict() *CacheEntry
	Name() string
}

// NewSmartCache åˆ›å»ºæ™ºèƒ½ç¼“å­˜
func NewSmartCache(config *CacheConfig) *SmartCache {
	if config == nil {
		config = DefaultCacheConfig()
	}

	shardCount := config.ShardCount
	if shardCount <= 0 {
		shardCount = 16
	}

	cache := &SmartCache{
		config:    config,
		logger:    zap.L().Named("smart-cache"),
		shards:    make([]*CacheShard, shardCount),
		shardMask: uint64(shardCount - 1),
	}

	// åˆå§‹åŒ–åˆ†ç‰‡
	shardMaxSize := config.MaxSize / int64(shardCount)
	shardMaxEntries := config.MaxEntries / shardCount

	for i := 0; i < shardCount; i++ {
		cache.shards[i] = &CacheShard{
			entries:    make(map[string]*CacheEntry),
			maxSize:    shardMaxSize,
			maxEntries: shardMaxEntries,
			policy:     createEvictionPolicy(config.EvictionPolicy),
		}
		cache.initLRUList(cache.shards[i])
	}

	// åˆå§‹åŒ–é¢„å–å™¨
	if config.EnablePrefetch {
		cache.prefetcher = NewPrefetcher(config, cache)
	}

	return cache
}

// Start å¯åŠ¨ç¼“å­˜
func (sc *SmartCache) Start(ctx context.Context) error {
	sc.ctx, sc.cancel = context.WithCancel(ctx)

	// å¯åŠ¨æ¸…ç†åç¨‹
	sc.wg.Add(1)
	go sc.cleanupLoop()

	// å¯åŠ¨ç»Ÿè®¡åç¨‹
	sc.wg.Add(1)
	go sc.statsLoop()

	// å¯åŠ¨é¢„å–å™¨
	if sc.prefetcher != nil {
		if err := sc.prefetcher.Start(sc.ctx); err != nil {
			return fmt.Errorf("å¯åŠ¨é¢„å–å™¨å¤±è´¥: %w", err)
		}
	}

	sc.logger.Info("ğŸ—„ï¸ æ™ºèƒ½ç¼“å­˜å¯åŠ¨",
		zap.Int64("max_size_mb", sc.config.MaxSize/1024/1024),
		zap.Int("max_entries", sc.config.MaxEntries),
		zap.String("eviction_policy", sc.config.EvictionPolicy),
		zap.Int("shard_count", len(sc.shards)),
		zap.Bool("prefetch_enabled", sc.config.EnablePrefetch))

	return nil
}

// Stop åœæ­¢ç¼“å­˜
func (sc *SmartCache) Stop() error {
	sc.logger.Info("ğŸ›‘ æ­£åœ¨åœæ­¢æ™ºèƒ½ç¼“å­˜...")

	if sc.cancel != nil {
		sc.cancel()
	}

	// åœæ­¢é¢„å–å™¨
	if sc.prefetcher != nil {
		if err := sc.prefetcher.Stop(); err != nil {
			sc.logger.Error("åœæ­¢é¢„å–å™¨å¤±è´¥", zap.Error(err))
		}
	}

	// ç­‰å¾…åç¨‹ç»“æŸ
	sc.wg.Wait()

	// æ¸…ç†æ‰€æœ‰åˆ†ç‰‡
	for _, shard := range sc.shards {
		shard.mutex.Lock()
		shard.entries = make(map[string]*CacheEntry)
		shard.currentSize = 0
		sc.initLRUList(shard)
		shard.mutex.Unlock()
	}

	sc.logger.Info("âœ… æ™ºèƒ½ç¼“å­˜å·²åœæ­¢")
	return nil
}

// Get è·å–ç¼“å­˜é¡¹
func (sc *SmartCache) Get(key string) ([]byte, error) {
	shard := sc.getShard(key)

	shard.mutex.RLock()
	entry, exists := shard.entries[key]
	shard.mutex.RUnlock()

	if !exists {
		sc.stats.misses.Add(1)

		// è§¦å‘é¢„å–
		if sc.prefetcher != nil {
			sc.prefetcher.OnMiss(key)
		}

		return nil, ErrCacheNotFound
	}

	// æ£€æŸ¥è¿‡æœŸ
	if entry.IsExpired() {
		sc.Delete(key)
		sc.stats.misses.Add(1)
		return nil, ErrCacheExpired
	}

	// æ›´æ–°è®¿é—®ä¿¡æ¯
	shard.mutex.Lock()
	entry.AccessedAt = time.Now()
	entry.AccessCount++
	shard.policy.OnAccess(entry)
	sc.moveToFront(shard, entry)
	shard.mutex.Unlock()

	sc.stats.hits.Add(1)

	// è§¦å‘é¢„å–
	if sc.prefetcher != nil {
		sc.prefetcher.OnHit(key)
	}

	// è§£å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰
	if entry.Compressed {
		return sc.decompress(entry.Value)
	}

	return entry.Value, nil
}

// Set è®¾ç½®ç¼“å­˜é¡¹
func (sc *SmartCache) Set(key string, value []byte, ttl time.Duration) error {
	if len(value) == 0 {
		return fmt.Errorf("ç¼“å­˜å€¼ä¸èƒ½ä¸ºç©º")
	}

	// å‹ç¼©ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	finalValue := value
	compressed := false
	if sc.config.EnableCompression && len(value) > 1024 {
		if compressedValue, err := sc.compress(value); err == nil && len(compressedValue) < len(value) {
			finalValue = compressedValue
			compressed = true
		}
	}

	entry := &CacheEntry{
		Key:         key,
		Value:       finalValue,
		Size:        int64(len(finalValue)),
		TTL:         ttl,
		CreatedAt:   time.Now(),
		AccessedAt:  time.Now(),
		AccessCount: 1,
		Compressed:  compressed,
	}

	if ttl <= 0 {
		entry.TTL = sc.config.DefaultTTL
	}

	shard := sc.getShard(key)

	shard.mutex.Lock()
	defer shard.mutex.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
	if oldEntry, exists := shard.entries[key]; exists {
		// æ›´æ–°ç°æœ‰æ¡ç›®
		shard.currentSize -= oldEntry.Size
		sc.removeFromLRU(shard, oldEntry)
	}

	// æ£€æŸ¥å®¹é‡é™åˆ¶
	if err := sc.ensureCapacity(shard, entry.Size); err != nil {
		return err
	}

	// æ·»åŠ æ–°æ¡ç›®
	shard.entries[key] = entry
	shard.currentSize += entry.Size
	shard.policy.OnAdd(entry)
	sc.addToFront(shard, entry)

	// æ›´æ–°ç»Ÿè®¡
	sc.stats.currentSize.Add(entry.Size)
	sc.stats.currentCount.Add(1)

	return nil
}

// Delete åˆ é™¤ç¼“å­˜é¡¹
func (sc *SmartCache) Delete(key string) error {
	shard := sc.getShard(key)

	shard.mutex.Lock()
	defer shard.mutex.Unlock()

	entry, exists := shard.entries[key]
	if !exists {
		return ErrCacheNotFound
	}

	delete(shard.entries, key)
	shard.currentSize -= entry.Size
	sc.removeFromLRU(shard, entry)

	// æ›´æ–°ç»Ÿè®¡
	sc.stats.currentSize.Add(-entry.Size)
	sc.stats.currentCount.Add(-1)

	return nil
}

// Exists æ£€æŸ¥ç¼“å­˜é¡¹æ˜¯å¦å­˜åœ¨
func (sc *SmartCache) Exists(key string) bool {
	shard := sc.getShard(key)

	shard.mutex.RLock()
	entry, exists := shard.entries[key]
	shard.mutex.RUnlock()

	if !exists {
		return false
	}

	return !entry.IsExpired()
}

// Clear æ¸…ç©ºç¼“å­˜
func (sc *SmartCache) Clear() error {
	for _, shard := range sc.shards {
		shard.mutex.Lock()
		shard.entries = make(map[string]*CacheEntry)
		shard.currentSize = 0
		sc.initLRUList(shard)
		shard.mutex.Unlock()
	}

	// é‡ç½®ç»Ÿè®¡
	sc.stats.currentSize.Store(0)
	sc.stats.currentCount.Store(0)

	sc.logger.Info("ğŸ§¹ ç¼“å­˜å·²æ¸…ç©º")
	return nil
}

// getShard è·å–åˆ†ç‰‡
func (sc *SmartCache) getShard(key string) *CacheShard {
	hash := sc.hash(key)
	return sc.shards[hash&sc.shardMask]
}

// hash è®¡ç®—å“ˆå¸Œå€¼
func (sc *SmartCache) hash(key string) uint64 {
	h := md5.Sum([]byte(key))
	return uint64(h[0])<<56 | uint64(h[1])<<48 | uint64(h[2])<<40 | uint64(h[3])<<32 |
		uint64(h[4])<<24 | uint64(h[5])<<16 | uint64(h[6])<<8 | uint64(h[7])
}

// ensureCapacity ç¡®ä¿å®¹é‡è¶³å¤Ÿ
func (sc *SmartCache) ensureCapacity(shard *CacheShard, newSize int64) error {
	// æ£€æŸ¥å•ä¸ªæ¡ç›®å¤§å°
	if newSize > shard.maxSize {
		return fmt.Errorf("æ¡ç›®å¤§å°è¶…è¿‡åˆ†ç‰‡é™åˆ¶: %d > %d", newSize, shard.maxSize)
	}

	// æ£€æŸ¥æ¡ç›®æ•°é‡
	if len(shard.entries) >= shard.maxEntries {
		if err := sc.evictEntries(shard, 1); err != nil {
			return err
		}
	}

	// æ£€æŸ¥å†…å­˜å¤§å°
	for shard.currentSize+newSize > shard.maxSize {
		if err := sc.evictEntries(shard, 1); err != nil {
			return err
		}
	}

	return nil
}

// evictEntries æ·˜æ±°æ¡ç›®
func (sc *SmartCache) evictEntries(shard *CacheShard, count int) error {
	for i := 0; i < count; i++ {
		entry := shard.policy.OnEvict()
		if entry == nil {
			// å°è¯•ä»LRUå°¾éƒ¨æ·˜æ±°
			entry = shard.lruTail
			if entry == nil {
				return ErrCacheFull
			}
		}

		delete(shard.entries, entry.Key)
		shard.currentSize -= entry.Size
		sc.removeFromLRU(shard, entry)

		sc.stats.evictions.Add(1)
		sc.stats.currentSize.Add(-entry.Size)
		sc.stats.currentCount.Add(-1)
	}

	return nil
}

// LRUé“¾è¡¨æ“ä½œ
func (sc *SmartCache) initLRUList(shard *CacheShard) {
	shard.lruHead = &CacheEntry{}
	shard.lruTail = &CacheEntry{}
	shard.lruHead.next = shard.lruTail
	shard.lruTail.prev = shard.lruHead
}

func (sc *SmartCache) addToFront(shard *CacheShard, entry *CacheEntry) {
	entry.next = shard.lruHead.next
	entry.prev = shard.lruHead
	shard.lruHead.next.prev = entry
	shard.lruHead.next = entry
}

func (sc *SmartCache) removeFromLRU(shard *CacheShard, entry *CacheEntry) {
	if entry.prev != nil {
		entry.prev.next = entry.next
	}
	if entry.next != nil {
		entry.next.prev = entry.prev
	}
	entry.prev = nil
	entry.next = nil
}

func (sc *SmartCache) moveToFront(shard *CacheShard, entry *CacheEntry) {
	sc.removeFromLRU(shard, entry)
	sc.addToFront(shard, entry)
}

// å‹ç¼©å’Œè§£å‹ç¼©
func (sc *SmartCache) compress(data []byte) ([]byte, error) {
	// ç®€åŒ–çš„å‹ç¼©å®ç°
	// å®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨gzipã€lz4ç­‰å‹ç¼©ç®—æ³•
	return data, nil
}

func (sc *SmartCache) decompress(data []byte) ([]byte, error) {
	// ç®€åŒ–çš„è§£å‹ç¼©å®ç°
	return data, nil
}

// cleanupLoop æ¸…ç†å¾ªç¯
func (sc *SmartCache) cleanupLoop() {
	defer sc.wg.Done()

	ticker := time.NewTicker(sc.config.CleanInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			sc.cleanup()
		case <-sc.ctx.Done():
			return
		}
	}
}

// cleanup æ¸…ç†è¿‡æœŸæ¡ç›®
func (sc *SmartCache) cleanup() {
	var totalCleaned int64

	for _, shard := range sc.shards {
		shard.mutex.Lock()

		var toDelete []string
		for key, entry := range shard.entries {
			if entry.IsExpired() {
				toDelete = append(toDelete, key)
			}
		}

		for _, key := range toDelete {
			entry := shard.entries[key]
			delete(shard.entries, key)
			shard.currentSize -= entry.Size
			sc.removeFromLRU(shard, entry)
			totalCleaned++
		}

		shard.mutex.Unlock()
	}

	if totalCleaned > 0 {
		sc.stats.currentCount.Add(-totalCleaned)
		sc.logger.Debug("ğŸ§¹ æ¸…ç†è¿‡æœŸæ¡ç›®", zap.Int64("count", totalCleaned))
	}
}

// statsLoop ç»Ÿè®¡å¾ªç¯
func (sc *SmartCache) statsLoop() {
	defer sc.wg.Done()

	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			sc.logStats()
		case <-sc.ctx.Done():
			return
		}
	}
}

// logStats è®°å½•ç»Ÿè®¡ä¿¡æ¯
func (sc *SmartCache) logStats() {
	stats := sc.GetStats()

	sc.logger.Info("ğŸ“Š ç¼“å­˜ç»Ÿè®¡",
		zap.Int64("hits", stats["hits"].(int64)),
		zap.Int64("misses", stats["misses"].(int64)),
		zap.Float64("hit_rate", stats["hit_rate"].(float64)),
		zap.Int64("entries", stats["entries"].(int64)),
		zap.Int64("size_mb", stats["size_mb"].(int64)),
		zap.Int64("evictions", stats["evictions"].(int64)))
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (sc *SmartCache) GetStats() map[string]interface{} {
	hits := sc.stats.hits.Load()
	misses := sc.stats.misses.Load()

	var hitRate float64
	if hits+misses > 0 {
		hitRate = float64(hits) / float64(hits+misses)
	}

	stats := map[string]interface{}{
		"hits":       hits,
		"misses":     misses,
		"hit_rate":   hitRate,
		"evictions":  sc.stats.evictions.Load(),
		"prefetches": sc.stats.prefetches.Load(),
		"entries":    sc.stats.currentCount.Load(),
		"size":       sc.stats.currentSize.Load(),
		"size_mb":    sc.stats.currentSize.Load() / 1024 / 1024,
		"config":     sc.config,
	}

	// æ·»åŠ é¢„å–å™¨ç»Ÿè®¡
	if sc.prefetcher != nil {
		stats["prefetcher"] = sc.prefetcher.GetStats()
	}

	return stats
}

// GetSize è·å–å½“å‰å¤§å°
func (sc *SmartCache) GetSize() int64 {
	return sc.stats.currentSize.Load()
}

// GetCount è·å–å½“å‰æ¡ç›®æ•°
func (sc *SmartCache) GetCount() int64 {
	return sc.stats.currentCount.Load()
}

// å…¨å±€ç¼“å­˜å®ä¾‹
var (
	globalCache     *SmartCache
	globalCacheOnce sync.Once
)

// GetGlobalCache è·å–å…¨å±€ç¼“å­˜
func GetGlobalCache() *SmartCache {
	globalCacheOnce.Do(func() {
		globalCache = NewSmartCache(DefaultCacheConfig())
	})
	return globalCache
}
