package protocol

import (
	"context"
	"fmt"
	"io"
	"sync"
	"sync/atomic"
	"time"

	"go.uber.org/zap"
)

// BatchConfig æ‰¹å¤„ç†é…ç½®
type BatchConfig struct {
	// æ‰¹å¤„ç†å‚æ•°
	MaxBatchSize   int           `json:"max_batch_size"`   // æœ€å¤§æ‰¹æ¬¡å¤§å°
	MaxBatchDelay  time.Duration `json:"max_batch_delay"`  // æœ€å¤§æ‰¹æ¬¡å»¶è¿Ÿ
	MaxMemoryUsage int           `json:"max_memory_usage"` // æœ€å¤§å†…å­˜ä½¿ç”¨
	FlushThreshold float64       `json:"flush_threshold"`  // åˆ·æ–°é˜ˆå€¼ï¼ˆå†…å­˜ä½¿ç”¨ç‡ï¼‰

	// å¹¶å‘æ§åˆ¶
	MaxWorkers     int           `json:"max_workers"`      // æœ€å¤§å·¥ä½œåç¨‹æ•°
	QueueSize      int           `json:"queue_size"`       // é˜Ÿåˆ—å¤§å°
	WorkerIdleTime time.Duration `json:"worker_idle_time"` // å·¥ä½œåç¨‹ç©ºé—²æ—¶é—´

	// æ€§èƒ½è°ƒä¼˜
	EnableCompression bool `json:"enable_compression"` // å¯ç”¨å‹ç¼©
	CompressionLevel  int  `json:"compression_level"`  // å‹ç¼©çº§åˆ«
	EnablePriority    bool `json:"enable_priority"`    // å¯ç”¨ä¼˜å…ˆçº§å¤„ç†
	AdaptiveBatching  bool `json:"adaptive_batching"`  // è‡ªé€‚åº”æ‰¹å¤„ç†
}

// DefaultBatchConfig é»˜è®¤æ‰¹å¤„ç†é…ç½®
func DefaultBatchConfig() *BatchConfig {
	return &BatchConfig{
		MaxBatchSize:      1000,
		MaxBatchDelay:     10 * time.Millisecond,
		MaxMemoryUsage:    128 * 1024 * 1024, // 128MB
		FlushThreshold:    0.8,               // 80%
		MaxWorkers:        4,
		QueueSize:         10000,
		WorkerIdleTime:    30 * time.Second,
		EnableCompression: true,
		CompressionLevel:  6,
		EnablePriority:    true,
		AdaptiveBatching:  true,
	}
}

// BatchProcessor æ‰¹å¤„ç†å™¨
type BatchProcessor struct {
	config *BatchConfig
	logger *zap.Logger

	// å·¥ä½œé˜Ÿåˆ—
	workQueue  chan *BatchItem
	batchQueue chan *Batch

	// å·¥ä½œåç¨‹ç®¡ç†
	workers      sync.WaitGroup
	batchWorkers sync.WaitGroup

	// æ‰¹æ¬¡ç®¡ç†
	currentBatch *Batch
	batchMutex   sync.Mutex
	batchTimer   *time.Timer

	// ç»Ÿè®¡ä¿¡æ¯
	stats struct {
		itemsProcessed   atomic.Int64
		batchesProcessed atomic.Int64
		totalLatency     atomic.Int64
		avgBatchSize     atomic.Int64
		compressionRatio atomic.Int64 // * 1000 for precision
		memoryUsage      atomic.Int64
		queueLength      atomic.Int64
	}

	// æ§åˆ¶
	ctx    context.Context
	cancel context.CancelFunc
}

// BatchItem æ‰¹å¤„ç†é¡¹
type BatchItem struct {
	ID        string
	Data      []byte
	Priority  int
	Timestamp time.Time
	Metadata  map[string]interface{}
	Callback  func(item *BatchItem, result *BatchResult)

	// å†…éƒ¨å­—æ®µ
	size       int
	compressed bool
}

// Batch æ‰¹æ¬¡
type Batch struct {
	ID        string
	Items     []*BatchItem
	CreatedAt time.Time
	Size      int
	Priority  int // æ‰¹æ¬¡ä¼˜å…ˆçº§ï¼ˆæœ€é«˜ä¼˜å…ˆçº§é¡¹çš„ä¼˜å…ˆçº§ï¼‰

	// ç»Ÿè®¡
	ItemCount      int
	TotalSize      int
	CompressedSize int
	ProcessingTime time.Duration
}

// BatchResult æ‰¹å¤„ç†ç»“æœ
type BatchResult struct {
	Success        bool
	ProcessedCount int
	FailedCount    int
	TotalSize      int64
	ProcessingTime time.Duration
	Error          error
	Metadata       map[string]interface{}
}

// BatchHandler æ‰¹å¤„ç†å¤„ç†å™¨æ¥å£
type BatchHandler interface {
	ProcessBatch(batch *Batch) *BatchResult
	GetHandlerType() string
}

// NewBatchProcessor åˆ›å»ºæ‰¹å¤„ç†å™¨
func NewBatchProcessor(config *BatchConfig) *BatchProcessor {
	if config == nil {
		config = DefaultBatchConfig()
	}

	processor := &BatchProcessor{
		config:     config,
		logger:     zap.L().Named("batch-processor"),
		workQueue:  make(chan *BatchItem, config.QueueSize),
		batchQueue: make(chan *Batch, config.MaxWorkers*2),
	}

	return processor
}

// Start å¯åŠ¨æ‰¹å¤„ç†å™¨
func (bp *BatchProcessor) Start(ctx context.Context) error {
	bp.ctx, bp.cancel = context.WithCancel(ctx)

	// å¯åŠ¨æ‰¹æ¬¡æ”¶é›†å™¨
	bp.workers.Add(1)
	go bp.batchCollector()

	// å¯åŠ¨æ‰¹å¤„ç†å·¥ä½œåç¨‹
	for i := 0; i < bp.config.MaxWorkers; i++ {
		bp.batchWorkers.Add(1)
		go bp.batchWorker(i)
	}

	// å¯åŠ¨ç›‘æ§åç¨‹
	bp.workers.Add(1)
	go bp.monitorLoop()

	bp.logger.Info("ğŸ“¦ æ‰¹å¤„ç†å™¨å¯åŠ¨",
		zap.Int("max_batch_size", bp.config.MaxBatchSize),
		zap.Duration("max_delay", bp.config.MaxBatchDelay),
		zap.Int("workers", bp.config.MaxWorkers),
		zap.Bool("compression", bp.config.EnableCompression))

	return nil
}

// Stop åœæ­¢æ‰¹å¤„ç†å™¨
func (bp *BatchProcessor) Stop() error {
	bp.logger.Info("ğŸ›‘ æ­£åœ¨åœæ­¢æ‰¹å¤„ç†å™¨...")

	if bp.cancel != nil {
		bp.cancel()
	}

	// å¤„ç†å‰©ä½™çš„æ‰¹æ¬¡
	bp.flushCurrentBatch()

	// å…³é—­é˜Ÿåˆ—
	close(bp.workQueue)

	// ç­‰å¾…å·¥ä½œåç¨‹ç»“æŸ
	bp.workers.Wait()

	// å…³é—­æ‰¹å¤„ç†é˜Ÿåˆ—
	close(bp.batchQueue)
	bp.batchWorkers.Wait()

	bp.logger.Info("âœ… æ‰¹å¤„ç†å™¨å·²åœæ­¢")
	return nil
}

// Submit æäº¤æ‰¹å¤„ç†é¡¹
func (bp *BatchProcessor) Submit(item *BatchItem) error {
	if item == nil {
		return fmt.Errorf("æ‰¹å¤„ç†é¡¹ä¸èƒ½ä¸ºç©º")
	}

	// è®¾ç½®é»˜è®¤å€¼
	if item.ID == "" {
		item.ID = fmt.Sprintf("item-%d", time.Now().UnixNano())
	}
	if item.Timestamp.IsZero() {
		item.Timestamp = time.Now()
	}
	if item.size == 0 {
		item.size = len(item.Data)
	}

	// æ›´æ–°é˜Ÿåˆ—é•¿åº¦ç»Ÿè®¡
	bp.stats.queueLength.Store(int64(len(bp.workQueue)))

	select {
	case bp.workQueue <- item:
		return nil
	case <-bp.ctx.Done():
		return bp.ctx.Err()
	default:
		return fmt.Errorf("å·¥ä½œé˜Ÿåˆ—å·²æ»¡")
	}
}

// SubmitAsync å¼‚æ­¥æäº¤æ‰¹å¤„ç†é¡¹
func (bp *BatchProcessor) SubmitAsync(item *BatchItem) {
	go func() {
		if err := bp.Submit(item); err != nil {
			bp.logger.Error("å¼‚æ­¥æäº¤å¤±è´¥",
				zap.String("item_id", item.ID),
				zap.Error(err))

			if item.Callback != nil {
				item.Callback(item, &BatchResult{
					Success: false,
					Error:   err,
				})
			}
		}
	}()
}

// batchCollector æ‰¹æ¬¡æ”¶é›†å™¨
func (bp *BatchProcessor) batchCollector() {
	defer bp.workers.Done()

	bp.logger.Debug("å¯åŠ¨æ‰¹æ¬¡æ”¶é›†å™¨")

	for {
		select {
		case item := <-bp.workQueue:
			bp.addToBatch(item)

		case <-bp.ctx.Done():
			bp.flushCurrentBatch()
			return
		}
	}
}

// addToBatch æ·»åŠ åˆ°æ‰¹æ¬¡
func (bp *BatchProcessor) addToBatch(item *BatchItem) {
	bp.batchMutex.Lock()
	defer bp.batchMutex.Unlock()

	// åˆ›å»ºæ–°æ‰¹æ¬¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
	if bp.currentBatch == nil {
		bp.createNewBatch()
	}

	// å‹ç¼©æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if bp.config.EnableCompression && !item.compressed {
		bp.compressItem(item)
	}

	// æ·»åŠ åˆ°å½“å‰æ‰¹æ¬¡
	bp.currentBatch.Items = append(bp.currentBatch.Items, item)
	bp.currentBatch.ItemCount++
	bp.currentBatch.TotalSize += item.size

	// æ›´æ–°æ‰¹æ¬¡ä¼˜å…ˆçº§
	if bp.config.EnablePriority && item.Priority > bp.currentBatch.Priority {
		bp.currentBatch.Priority = item.Priority
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ‰¹æ¬¡
	shouldFlush := bp.shouldFlushBatch()
	if shouldFlush {
		bp.flushCurrentBatchUnsafe()
	}
}

// createNewBatch åˆ›å»ºæ–°æ‰¹æ¬¡
func (bp *BatchProcessor) createNewBatch() {
	bp.currentBatch = &Batch{
		ID:        fmt.Sprintf("batch-%d", time.Now().UnixNano()),
		Items:     make([]*BatchItem, 0, bp.config.MaxBatchSize),
		CreatedAt: time.Now(),
		Priority:  0,
	}

	// è®¾ç½®åˆ·æ–°å®šæ—¶å™¨
	if bp.batchTimer != nil {
		bp.batchTimer.Stop()
	}
	bp.batchTimer = time.AfterFunc(bp.config.MaxBatchDelay, func() {
		bp.batchMutex.Lock()
		bp.flushCurrentBatchUnsafe()
		bp.batchMutex.Unlock()
	})
}

// shouldFlushBatch æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ·æ–°æ‰¹æ¬¡
func (bp *BatchProcessor) shouldFlushBatch() bool {
	if bp.currentBatch == nil {
		return false
	}

	// æ£€æŸ¥æ‰¹æ¬¡å¤§å°
	if bp.currentBatch.ItemCount >= bp.config.MaxBatchSize {
		return true
	}

	// æ£€æŸ¥å†…å­˜ä½¿ç”¨
	currentMemory := bp.stats.memoryUsage.Load()
	if float64(currentMemory) > float64(bp.config.MaxMemoryUsage)*bp.config.FlushThreshold {
		return true
	}

	// è‡ªé€‚åº”æ‰¹å¤„ç†
	if bp.config.AdaptiveBatching {
		return bp.shouldAdaptiveFlush()
	}

	return false
}

// shouldAdaptiveFlush è‡ªé€‚åº”åˆ·æ–°åˆ¤æ–­
func (bp *BatchProcessor) shouldAdaptiveFlush() bool {
	// åŸºäºé˜Ÿåˆ—é•¿åº¦çš„è‡ªé€‚åº”ç­–ç•¥
	queueLen := bp.stats.queueLength.Load()
	avgBatchSize := bp.stats.avgBatchSize.Load()

	// å¦‚æœé˜Ÿåˆ—å¾ˆé•¿ï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡ä»¥å‡å°‘å»¶è¿Ÿ
	if queueLen > int64(bp.config.QueueSize/2) {
		return bp.currentBatch.ItemCount >= int(avgBatchSize/2)
	}

	// å¦‚æœé˜Ÿåˆ—å¾ˆçŸ­ï¼Œç­‰å¾…æ›´å¤§çš„æ‰¹æ¬¡ä»¥æé«˜æ•ˆç‡
	if queueLen < int64(bp.config.QueueSize/10) {
		return false
	}

	return false
}

// flushCurrentBatch åˆ·æ–°å½“å‰æ‰¹æ¬¡
func (bp *BatchProcessor) flushCurrentBatch() {
	bp.batchMutex.Lock()
	defer bp.batchMutex.Unlock()
	bp.flushCurrentBatchUnsafe()
}

// flushCurrentBatchUnsafe åˆ·æ–°å½“å‰æ‰¹æ¬¡ï¼ˆä¸å®‰å…¨ç‰ˆæœ¬ï¼‰
func (bp *BatchProcessor) flushCurrentBatchUnsafe() {
	if bp.currentBatch == nil || bp.currentBatch.ItemCount == 0 {
		return
	}

	// åœæ­¢å®šæ—¶å™¨
	if bp.batchTimer != nil {
		bp.batchTimer.Stop()
		bp.batchTimer = nil
	}

	// å‘é€æ‰¹æ¬¡åˆ°å¤„ç†é˜Ÿåˆ—
	select {
	case bp.batchQueue <- bp.currentBatch:
		bp.logger.Debug("æ‰¹æ¬¡å·²å‘é€åˆ°å¤„ç†é˜Ÿåˆ—",
			zap.String("batch_id", bp.currentBatch.ID),
			zap.Int("item_count", bp.currentBatch.ItemCount),
			zap.Int("total_size", bp.currentBatch.TotalSize))

	case <-bp.ctx.Done():
		bp.logger.Warn("ä¸Šä¸‹æ–‡å·²å–æ¶ˆï¼Œä¸¢å¼ƒæ‰¹æ¬¡",
			zap.String("batch_id", bp.currentBatch.ID))
	default:
		bp.logger.Warn("æ‰¹å¤„ç†é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ‰¹æ¬¡",
			zap.String("batch_id", bp.currentBatch.ID))
	}

	// æ›´æ–°ç»Ÿè®¡
	bp.updateBatchStats(bp.currentBatch)

	// é‡ç½®å½“å‰æ‰¹æ¬¡
	bp.currentBatch = nil
}

// batchWorker æ‰¹å¤„ç†å·¥ä½œåç¨‹
func (bp *BatchProcessor) batchWorker(id int) {
	defer bp.batchWorkers.Done()

	bp.logger.Debug("å¯åŠ¨æ‰¹å¤„ç†å·¥ä½œåç¨‹", zap.Int("worker_id", id))

	for batch := range bp.batchQueue {
		start := time.Now()
		result := bp.processBatch(batch)
		batch.ProcessingTime = time.Since(start)

		// æ›´æ–°ç»Ÿè®¡
		bp.stats.batchesProcessed.Add(1)
		bp.stats.totalLatency.Add(batch.ProcessingTime.Nanoseconds())

		// è°ƒç”¨å›è°ƒ
		bp.callItemCallbacks(batch, result)

		bp.logger.Debug("æ‰¹æ¬¡å¤„ç†å®Œæˆ",
			zap.String("batch_id", batch.ID),
			zap.Int("item_count", batch.ItemCount),
			zap.Duration("processing_time", batch.ProcessingTime),
			zap.Bool("success", result.Success))
	}

	bp.logger.Debug("æ‰¹å¤„ç†å·¥ä½œåç¨‹ç»“æŸ", zap.Int("worker_id", id))
}

// processBatch å¤„ç†æ‰¹æ¬¡
func (bp *BatchProcessor) processBatch(batch *Batch) *BatchResult {
	result := &BatchResult{
		Success:        true,
		ProcessedCount: 0,
		FailedCount:    0,
		TotalSize:      int64(batch.TotalSize),
		ProcessingTime: 0,
		Metadata:       make(map[string]interface{}),
	}

	start := time.Now()
	defer func() {
		result.ProcessingTime = time.Since(start)
	}()

	// å¤„ç†æ¯ä¸ªé¡¹ç›®
	for _, item := range batch.Items {
		if err := bp.processItem(item); err != nil {
			result.FailedCount++
			result.Success = false
			if result.Error == nil {
				result.Error = err
			}
			bp.logger.Error("å¤„ç†é¡¹ç›®å¤±è´¥",
				zap.String("item_id", item.ID),
				zap.Error(err))
		} else {
			result.ProcessedCount++
			bp.stats.itemsProcessed.Add(1)
		}
	}

	return result
}

// processItem å¤„ç†å•ä¸ªé¡¹ç›®
func (bp *BatchProcessor) processItem(item *BatchItem) error {
	// è¿™é‡Œæ˜¯å…·ä½“çš„å¤„ç†é€»è¾‘
	// å®é™…åº”ç”¨ä¸­ï¼Œè¿™ä¼šæ ¹æ®é¡¹ç›®ç±»å‹è¿›è¡Œä¸åŒçš„å¤„ç†

	// æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
	if item.size > 1024 {
		time.Sleep(time.Microsecond * time.Duration(item.size/1024))
	}

	return nil
}

// callItemCallbacks è°ƒç”¨é¡¹ç›®å›è°ƒ
func (bp *BatchProcessor) callItemCallbacks(batch *Batch, result *BatchResult) {
	for i, item := range batch.Items {
		if item.Callback != nil {
			itemResult := &BatchResult{
				Success:        i < result.ProcessedCount,
				ProcessedCount: 1,
				TotalSize:      int64(item.size),
				ProcessingTime: result.ProcessingTime / time.Duration(len(batch.Items)),
				Error:          result.Error,
			}

			go item.Callback(item, itemResult)
		}
	}
}

// compressItem å‹ç¼©é¡¹ç›®æ•°æ®
func (bp *BatchProcessor) compressItem(item *BatchItem) {
	// ç®€åŒ–çš„å‹ç¼©å®ç°
	// å®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨çœŸæ­£çš„å‹ç¼©ç®—æ³•
	if len(item.Data) > 128 {
		// æ¨¡æ‹Ÿå‹ç¼©
		originalSize := len(item.Data)
		compressedSize := originalSize * 7 / 10 // å‡è®¾70%çš„å‹ç¼©ç‡

		// æ›´æ–°å‹ç¼©ç»Ÿè®¡
		ratio := int64(compressedSize * 1000 / originalSize)
		bp.stats.compressionRatio.Store(ratio)

		item.size = compressedSize
		item.compressed = true

		bp.logger.Debug("æ•°æ®å·²å‹ç¼©",
			zap.String("item_id", item.ID),
			zap.Int("original_size", originalSize),
			zap.Int("compressed_size", compressedSize))
	}
}

// updateBatchStats æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
func (bp *BatchProcessor) updateBatchStats(batch *Batch) {
	// æ›´æ–°å¹³å‡æ‰¹æ¬¡å¤§å°
	oldAvg := bp.stats.avgBatchSize.Load()
	newAvg := (oldAvg*9 + int64(batch.ItemCount)) / 10
	bp.stats.avgBatchSize.Store(newAvg)

	// æ›´æ–°å†…å­˜ä½¿ç”¨
	bp.stats.memoryUsage.Add(int64(batch.TotalSize))
}

// monitorLoop ç›‘æ§å¾ªç¯
func (bp *BatchProcessor) monitorLoop() {
	defer bp.workers.Done()

	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			bp.logStats()
			bp.adjustParameters()

		case <-bp.ctx.Done():
			return
		}
	}
}

// logStats è®°å½•ç»Ÿè®¡ä¿¡æ¯
func (bp *BatchProcessor) logStats() {
	stats := bp.GetStats()

	bp.logger.Info("ğŸ“Š æ‰¹å¤„ç†å™¨ç»Ÿè®¡",
		zap.Int64("items_processed", stats["items_processed"].(int64)),
		zap.Int64("batches_processed", stats["batches_processed"].(int64)),
		zap.Float64("avg_batch_size", stats["avg_batch_size"].(float64)),
		zap.Float64("avg_latency_ms", stats["avg_latency_ms"].(float64)),
		zap.Int64("queue_length", stats["queue_length"].(int64)),
		zap.Float64("compression_ratio", stats["compression_ratio"].(float64)))
}

// adjustParameters è°ƒæ•´å‚æ•°
func (bp *BatchProcessor) adjustParameters() {
	if !bp.config.AdaptiveBatching {
		return
	}

	queueLen := bp.stats.queueLength.Load()
	avgLatency := float64(bp.stats.totalLatency.Load()) / 1e6 // è½¬æ¢ä¸ºæ¯«ç§’

	// å¦‚æœé˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œå‡å°æ‰¹æ¬¡å¤§å°
	if queueLen > int64(bp.config.QueueSize*3/4) {
		newSize := bp.config.MaxBatchSize * 3 / 4
		if newSize > 10 {
			bp.config.MaxBatchSize = newSize
			bp.logger.Info("ğŸ”§ è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆå‡å°ï¼‰", zap.Int("new_size", newSize))
		}
	}

	// å¦‚æœå»¶è¿Ÿè¿‡é«˜ï¼Œå‡å°æ‰¹æ¬¡å»¶è¿Ÿ
	if avgLatency > 100 { // 100ms
		newDelay := bp.config.MaxBatchDelay * 3 / 4
		if newDelay > time.Millisecond {
			bp.config.MaxBatchDelay = newDelay
			bp.logger.Info("ğŸ”§ è°ƒæ•´æ‰¹æ¬¡å»¶è¿Ÿï¼ˆå‡å°ï¼‰", zap.Duration("new_delay", newDelay))
		}
	}
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (bp *BatchProcessor) GetStats() map[string]interface{} {
	batchesProcessed := bp.stats.batchesProcessed.Load()
	var avgBatchSize float64
	var avgLatencyMs float64

	if batchesProcessed > 0 {
		avgBatchSize = float64(bp.stats.itemsProcessed.Load()) / float64(batchesProcessed)
		avgLatencyMs = float64(bp.stats.totalLatency.Load()) / float64(batchesProcessed) / 1e6
	}

	return map[string]interface{}{
		"items_processed":    bp.stats.itemsProcessed.Load(),
		"batches_processed":  batchesProcessed,
		"avg_batch_size":     avgBatchSize,
		"avg_latency_ms":     avgLatencyMs,
		"compression_ratio":  float64(bp.stats.compressionRatio.Load()) / 1000.0,
		"memory_usage":       bp.stats.memoryUsage.Load(),
		"queue_length":       bp.stats.queueLength.Load(),
		"current_batch_size": bp.getCurrentBatchSize(),
		"config":             bp.config,
	}
}

// getCurrentBatchSize è·å–å½“å‰æ‰¹æ¬¡å¤§å°
func (bp *BatchProcessor) getCurrentBatchSize() int {
	bp.batchMutex.Lock()
	defer bp.batchMutex.Unlock()

	if bp.currentBatch != nil {
		return bp.currentBatch.ItemCount
	}
	return 0
}

// CreateBatchItem åˆ›å»ºæ‰¹å¤„ç†é¡¹ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
func CreateBatchItem(data []byte, priority int, callback func(*BatchItem, *BatchResult)) *BatchItem {
	return &BatchItem{
		ID:        fmt.Sprintf("item-%d", time.Now().UnixNano()),
		Data:      data,
		Priority:  priority,
		Timestamp: time.Now(),
		Callback:  callback,
		size:      len(data),
	}
}

// BatchWriter æ‰¹å¤„ç†å†™å…¥å™¨
type BatchWriter struct {
	processor *BatchProcessor
	priority  int
	metadata  map[string]interface{}
}

// NewBatchWriter åˆ›å»ºæ‰¹å¤„ç†å†™å…¥å™¨
func NewBatchWriter(processor *BatchProcessor, priority int) *BatchWriter {
	return &BatchWriter{
		processor: processor,
		priority:  priority,
		metadata:  make(map[string]interface{}),
	}
}

// Write å®ç°io.Writeræ¥å£
func (bw *BatchWriter) Write(data []byte) (int, error) {
	item := &BatchItem{
		ID:        fmt.Sprintf("write-%d", time.Now().UnixNano()),
		Data:      make([]byte, len(data)),
		Priority:  bw.priority,
		Timestamp: time.Now(),
		Metadata:  bw.metadata,
		size:      len(data),
	}

	copy(item.Data, data)

	if err := bw.processor.Submit(item); err != nil {
		return 0, err
	}

	return len(data), nil
}

// SetMetadata è®¾ç½®å…ƒæ•°æ®
func (bw *BatchWriter) SetMetadata(key string, value interface{}) {
	bw.metadata[key] = value
}

// ç¡®ä¿å®ç°äº†æ¥å£
var _ io.Writer = (*BatchWriter)(nil)



